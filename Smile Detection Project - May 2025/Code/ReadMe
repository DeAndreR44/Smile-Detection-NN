Smile Detection with Neural Networks and Real-Time Face Tracking
Overview
This project implements a real-time smile detection system using a deep convolutional neural network (CNN) and MediaPipe for face tracking. It combines a powerful InceptionResNetV2 model with OpenCV and MediaPipe to detect smiles from live webcam input in a Jupyter Notebook environment.

Project Structure
smile-detection.ipynb: Trains a CNN model (InceptionResNetV2 base) for binary smile classification on a curated dataset.

4-13-25_FaceDetectionPythonCode (1).ipynb: Real-time inference script using OpenCV and MediaPipe for face tracking and live smile prediction.

Features
✅ Real-time smile detection using webcam video
✅ Pre-trained CNN with transfer learning
✅ Integrated face tracking with MediaPipe
✅ Data augmentation to improve generalization
✅ Fine-tuned for accuracy and lightweight deployment

Requirements
Python 3.7+

Jupyter Notebook

TensorFlow

Keras

OpenCV

MediaPipe

NumPy

Matplotlib

Install with:

bash
Copy
Edit
pip install tensorflow opencv-python mediapipe numpy matplotlib
Model Architecture
Base model: InceptionResNetV2 (pre-trained on ImageNet, top layers removed)

Custom classification head:

GlobalAveragePooling2D

Dense(512, ReLU)

Dropout (0.5)

Dense(1, Sigmoid)

Loss Function: Binary Crossentropy

Optimizer: Adam

Training: 30 epochs (frozen base), then 30 epochs (partial fine-tuning)

Callbacks:

ModelCheckpoint to save best model

EarlyStopping for overfitting prevention

ReduceLROnPlateau for adaptive learning rate

Dataset
The model was trained on a labeled image dataset for smile classification. It includes real-world images of smiling and neutral faces, with preprocessing and augmentation applied.

Dataset link:
Smile Detection Project 2025 on Kaggle
https://www.kaggle.com/datasets/deanyfjhtj/smile-detection-project-2025

Data Preprocessing
Image resize: 150×150

Rescale pixel values to [0, 1]

Augmentation: rotation, zoom, width/height shift, shear, flip

80/20 train-validation split via ImageDataGenerator

How to Use
Train the model
Open smile-detection.ipynb and run all cells to load, train, and save the smile detection model.

Run real-time detection
Open 4-13-25_FaceDetectionPythonCode (1).ipynb, ensure your webcam is connected, and execute all cells to start detecting smiles in real time.

Example Output
The system displays webcam video with bounding boxes and labels ("Smiling"/"Not Smiling") on detected faces.

Future Work
Deploy on Jetson Nano or Raspberry Pi for edge AI applications

Extend to emotion classification (e.g., happy, sad, surprised)

Improve dataset diversity to increase fairness and accuracy

Convert model to .tflite for mobile use

Author
DeAndre Robertson
Machine Learning Developer

BACKGROUND 

Smile Detection on Edge Devices — Project Overview
This project, developed by Happy Snap A.I., focuses on building a real-time smile detection system using convolutional neural networks (CNNs) optimized for edge computing platforms such as the Raspberry Pi. The goal is to enable accurate and efficient facial emotional recognition (FER) under diverse real-world conditions, with particular emphasis on automatically capturing selfies when a smile is detected.

Objectives
Develop a CNN-based model capable of real-time smile detection.

Optimize the model for edge deployment (e.g., Raspberry Pi, Jetson Nano).

Automatically trigger a camera to capture a photo upon smile detection.

Technical Approach
Model Architecture: EfficientNet was selected for its high accuracy and low computational cost.

Libraries and Frameworks: TensorFlow, Keras, Scikit-learn, OpenCV.

Face Detection: Transitioned from Mediapipe to HaarCascade on Raspberry Pi due to hardware limitations.

Data: Utilized public datasets from Kaggle, including smiling and non-smiling images. Applied image augmentation to improve robustness.

System Workflow
Capture live video feed from the camera.

Detect and crop the face region.

Preprocess the image and run inference using the trained CNN.

If a smile is detected, automatically capture and save a photo.

Key Achievements
High smile detection accuracy achieved in both controlled and natural environments.

Real-time processing successfully implemented on resource-constrained devices.

Demonstrated the viability of lightweight CNNs for facial expression recognition.

Challenges and Constraints
Latency and library limitations on Raspberry Pi impacted face detection and processing speed.

Dataset diversity limited model generalization; further data collection is needed.

Model training required significant time and computational resources.

Future Work
Expand dataset with greater expression variety to improve generalization.

Investigate more efficient face detection algorithms for embedded systems.

Dockerize the solution for improved portability and ease of deployment.

Ethical and Environmental Considerations
Ensuring user consent in any application involving facial recognition is essential.

Edge-based inference reduces reliance on cloud infrastructure, minimizing environmental impact and improving privacy.

